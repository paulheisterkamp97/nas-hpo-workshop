{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d2ab50e",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "574808c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.quasirandom import SobolEngine\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.optim.fit import fit_gpytorch_mll_torch\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a19405a",
   "metadata": {},
   "source": [
    "#### Define the Objective Function\n",
    "\n",
    "The objective function is the function you want to optimize. It takes hyperparameters as input and returns the model's cross-validation score as the output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "037301e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function\n",
    "# Function to minimize: f(x) = (x - 2)^2\n",
    "def objective_function(x):\n",
    "    return (x - 2) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b001fea",
   "metadata": {},
   "source": [
    "#### Set Up the Bayesian Optimizer\n",
    "\n",
    "Define the bounds for the hyperparameters and initialize the Bayesian optimizer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbe3eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Bayesian Optimization\n",
    "def bayesian_optimization():\n",
    "    # Step 1: Define the search space\n",
    "    bounds = torch.tensor([[0.0], [4.0]])  # Search space: x in [0, 4]\n",
    "\n",
    "    # Step 2: Generate initial data\n",
    "    num_initial_points = 5\n",
    "    sobol = SobolEngine(dimension=1, scramble=True)\n",
    "    train_x = sobol.draw(num_initial_points) * (bounds[1] - bounds[0]) + bounds[0]  # [N, d] tensor\n",
    "    train_y = objective_function(train_x)  # Compute objective values (shape: [N, 1])\n",
    "\n",
    "    # Step 3: Fit a Gaussian Process (GP) model\n",
    "    gp = SingleTaskGP(train_x, train_y)  # Ensure train_y is 2D with shape [N, 1]\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    fit_gpytorch_mll_torch(mll)\n",
    "\n",
    "    # Step 4: Optimization loop\n",
    "    num_iterations = 10\n",
    "    for i in range(num_iterations):\n",
    "        # Define the acquisition function\n",
    "        ei = ExpectedImprovement(gp, best_f=train_y.min())\n",
    "\n",
    "        # Optimize the acquisition function to propose the next point\n",
    "        candidate, _ = optimize_acqf(\n",
    "            acq_function=ei,\n",
    "            bounds=bounds,\n",
    "            q=1,  # Number of candidates to optimize for\n",
    "            num_restarts=10,\n",
    "            raw_samples=100,\n",
    "        )\n",
    "\n",
    "        # Evaluate the objective function at the candidate point\n",
    "        new_x = candidate.detach()\n",
    "        new_y = objective_function(new_x)  # Ensure new_y is 2D with shape [N, 1]\n",
    "\n",
    "        # Update the training data\n",
    "        train_x = torch.cat([train_x, new_x])  # Concatenate along rows\n",
    "        train_y = torch.cat([train_y, new_y])  # Concatenate along rows\n",
    "\n",
    "        # Refit the GP model\n",
    "        gp = SingleTaskGP(train_x, train_y)\n",
    "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "        fit_gpytorch_mll_torch(mll)\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Iteration {i + 1}: x = {new_x.item():.4f}, f(x) = {new_y.item():.4f}\")\n",
    "\n",
    "    # Step 5: Return the best result\n",
    "    best_index = train_y.argmin()\n",
    "    best_x = train_x[best_index].item()  # Convert tensor to scalar\n",
    "    best_y = train_y[best_index].item()  # Convert tensor to scalar\n",
    "    return best_x, best_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352600cb",
   "metadata": {},
   "source": [
    "#### Run the Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "762d150a",
   "metadata": {},
   "outputs": [
    {
     "ename": "BotorchTensorDimensionError",
     "evalue": "Expected X and Y to have the same number of dimensions (got X with dimension 2 and Y with dimension 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBotorchTensorDimensionError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run the Bayesian Optimization\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m best_x, best_y = \u001b[43mbayesian_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOptimal x: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_x\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Optimal f(x): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_y\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mbayesian_optimization\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     10\u001b[39m train_y = ((train_x - \u001b[32m2\u001b[39m) ** \u001b[32m2\u001b[39m).unsqueeze(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# Ensure train_y is 2D\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Step 3: Fit a Gaussian Process (GP) model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m gp = \u001b[43mSingleTaskGP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n\u001b[32m     15\u001b[39m fit_gpytorch_mll_torch(mll)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hpo_workshop/.venv/lib/python3.13/site-packages/botorch/models/gp_regression.py:157\u001b[39m, in \u001b[36mSingleTaskGP.__init__\u001b[39m\u001b[34m(self, train_X, train_Y, train_Yvar, likelihood, covar_module, mean_module, outcome_transform, input_transform)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    123\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    124\u001b[39m     train_X: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    131\u001b[39m     input_transform: InputTransform | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    132\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    133\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[33;03m        train_X: A `batch_shape x n x d` tensor of training features.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    155\u001b[39m \u001b[33;03m            forward pass.\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_tensor_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYvar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_Yvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m outcome_transform == DEFAULT:\n\u001b[32m    159\u001b[39m         outcome_transform = Standardize(\n\u001b[32m    160\u001b[39m             m=train_Y.shape[-\u001b[32m1\u001b[39m], batch_shape=train_X.shape[:-\u001b[32m2\u001b[39m]\n\u001b[32m    161\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hpo_workshop/.venv/lib/python3.13/site-packages/botorch/models/gpytorch.py:104\u001b[39m, in \u001b[36mGPyTorchModel._validate_tensor_args\u001b[39m\u001b[34m(X, Y, Yvar, strict)\u001b[39m\n\u001b[32m     98\u001b[39m     message = (\n\u001b[32m     99\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExpected X and Y to have the same number of dimensions\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m (got X with dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX.dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and Y with dimension\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY.dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    102\u001b[39m     )\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BotorchTensorDimensionError(message)\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    106\u001b[39m     warnings.warn(\n\u001b[32m    107\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNon-strict enforcement of botorch tensor conventions. The \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    108\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfollowing error would have been raised with strict enforcement: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    111\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    112\u001b[39m     )\n",
      "\u001b[31mBotorchTensorDimensionError\u001b[39m: Expected X and Y to have the same number of dimensions (got X with dimension 2 and Y with dimension 3)."
     ]
    }
   ],
   "source": [
    "# Run the Bayesian Optimization\n",
    "best_x, best_y = bayesian_optimization()\n",
    "print(f\"Optimal x: {best_x}, Optimal f(x): {best_y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411ecdd2",
   "metadata": {},
   "source": [
    "#### Advantages of Bayesian Optimization\n",
    "Efficiency: It finds good hyperparameters with fewer iterations compared to Grid Search or Random Search.  \n",
    "Balance of Exploration and Exploitation: Bayesian optimization intelligently balances exploring new areas of the hyperparameter space and exploiting areas that have already shown promise.  \n",
    "Works with Noisy Objectives: It performs well even when the objective function is noisy (e.g., stochastic models).  \n",
    "\n",
    "#### When to Use Bayesian Optimization\n",
    "When the hyperparameter space is large or contains continuous variables.  \n",
    "When computational resources are limited, and you want to optimize efficiently.  \n",
    "For machine learning models where training is expensive (e.g., deep learning).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
